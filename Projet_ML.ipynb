{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1xgh0_Q6ZR94FmDZg_qYmGJc_5h2jCGNO",
      "authorship_tag": "ABX9TyMtnNOoTHYLfXM9FayXbpfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lounisob/implementation_ml/blob/main/Projet_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPEC CPU:"
      ],
      "metadata": {
        "id": "k2THa6AHxyss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo\n",
        "print(\"----------\")\n",
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRle4VZLxyXZ",
        "outputId": "0465e916-640b-4e91-d776-1af5beae414f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "----------\n",
            "MemTotal:       13302912 kB\n",
            "MemFree:        10617212 kB\n",
            "MemAvailable:   12459552 kB\n",
            "Buffers:          132560 kB\n",
            "Cached:          1855400 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1065068 kB\n",
            "Inactive:        1425792 kB\n",
            "Active(anon):     450844 kB\n",
            "Inactive(anon):      500 kB\n",
            "Active(file):     614224 kB\n",
            "Inactive(file):  1425292 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               912 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        503004 kB\n",
            "Mapped:           267692 kB\n",
            "Shmem:              1180 kB\n",
            "KReclaimable:      88808 kB\n",
            "Slab:             131768 kB\n",
            "SReclaimable:      88808 kB\n",
            "SUnreclaim:        42960 kB\n",
            "KernelStack:        6048 kB\n",
            "PageTables:         7600 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6651456 kB\n",
            "Committed_AS:    3686184 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:        8548 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1448 kB\n",
            "AnonHugePages:      2048 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:       92992 kB\n",
            "DirectMap2M:     5146624 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour afficher les infos sur le GPU que Colab utilise (Tesla K80)"
      ],
      "metadata": {
        "id": "rhDsqL-BOJuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clvEYhO9MbD3",
        "outputId": "8adfe1e4-7169-467c-eaea-87a61a479693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 25 06:35:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "NPOIQyWgzH1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version sequentielle de ViolaJones\n",
        "\n",
        "Source:https://github.com/aparande/FaceDetection"
      ],
      "metadata": {
        "id": "wNlmWh38OhPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvlznOFEMBYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c639d93-9957-4242-b842-f85303e48a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing integral images\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 7.18 s (started: 2022-03-25 06:39:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!python drive/MyDrive/FaceDetection/viola_jones.py \n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version GPU :"
      ],
      "metadata": {
        "id": "S4wbQEvrOxIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python drive/MyDrive/FaceDetection/viola_jones_gpu.py \n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlIHXzilOz6g",
        "outputId": "dcdcfb97-ac31-4376-a7f8-3f0b53958af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing integral images\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 4.42 s (started: 2022-03-25 06:39:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projet IMPLEMENTATION ML\n",
        "Par Lounis Ould Bouali"
      ],
      "metadata": {
        "id": "ot8OLkfMMTAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code ci-dessous a été développer au cours des TPs:\n",
        "La fonction transpose a été prises sur le github officiel de numba qui est une version optimisé."
      ],
      "metadata": {
        "id": "cbS4SewmJciu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "from numba.cuda.cudadrv.driver import driver\n",
        "from numba.np import numpy_support as nps\n",
        "import numba as nb\n",
        "import numpy as np\n",
        "import math\n",
        "from math import *\n",
        "\n",
        "\n",
        "# Source: https://github.com/numba/numba/blob/main/numba/cuda/kernels/transpose.py\n",
        "def transpose(a, b=None):\n",
        "    \"\"\"Compute the transpose of 'a' and store it into 'b', if given,\n",
        "    and return it. If 'b' is not given, allocate a new array\n",
        "    and return that.\n",
        "    This implements the algorithm documented in\n",
        "    http://devblogs.nvidia.com/parallelforall/efficient-matrix-transpose-cuda-cc/\n",
        "    :param a: an `np.ndarray` or a `DeviceNDArrayBase` subclass. If already on\n",
        "        the device its stream will be used to perform the transpose (and to copy\n",
        "        `b` to the device if necessary).\n",
        "    \"\"\"\n",
        "\n",
        "    # prefer `a`'s stream if\n",
        "    stream = getattr(a, 'stream', 0)\n",
        "\n",
        "    if not b:\n",
        "        cols, rows = a.shape\n",
        "        strides = a.dtype.itemsize * cols, a.dtype.itemsize\n",
        "        b = cuda.cudadrv.devicearray.DeviceNDArray(\n",
        "            (rows, cols),\n",
        "            strides,\n",
        "            dtype=a.dtype,\n",
        "            stream=stream)\n",
        "\n",
        "    dt = nps.from_dtype(a.dtype)\n",
        "\n",
        "    tpb = driver.get_device().MAX_THREADS_PER_BLOCK\n",
        "    # we need to factor available threads into x and y axis\n",
        "    tile_width = int(math.pow(2, math.log(tpb, 2) / 2))\n",
        "    tile_height = int(tpb / tile_width)\n",
        "\n",
        "    tile_shape = (tile_height, tile_width + 1)\n",
        "\n",
        "    @cuda.jit\n",
        "    def kernel(input, output):\n",
        "\n",
        "        tile = cuda.shared.array(shape=tile_shape, dtype=dt)\n",
        "\n",
        "        tx = cuda.threadIdx.x\n",
        "        ty = cuda.threadIdx.y\n",
        "        bx = cuda.blockIdx.x * cuda.blockDim.x\n",
        "        by = cuda.blockIdx.y * cuda.blockDim.y\n",
        "        x = by + tx\n",
        "        y = bx + ty\n",
        "\n",
        "        if by + ty < input.shape[0] and bx + tx < input.shape[1]:\n",
        "            tile[ty, tx] = input[by + ty, bx + tx]\n",
        "        cuda.syncthreads()\n",
        "        if y < output.shape[0] and x < output.shape[1]:\n",
        "            output[y, x] = tile[tx, ty]\n",
        "\n",
        "    # one block per tile, plus one for remainders\n",
        "    blocks = int(b.shape[0] / tile_height + 1), int(b.shape[1] / tile_width + 1)\n",
        "    # one thread per tile element\n",
        "    threads = tile_height, tile_width\n",
        "    kernel[blocks, threads, stream](a, b)\n",
        "\n",
        "    return b\n",
        "\n",
        "@cuda.jit\n",
        "def kernel(s_tab,N,m,sum_tab):\n",
        "      \n",
        "      local_id = cuda.threadIdx.x\n",
        "      blockIdx_x = cuda.blockIdx.x\n",
        "      blockDimx_x = cuda.blockDim.x\n",
        "      #global_id = cuda.grid(1)\n",
        "\n",
        "      # Montée\n",
        "      for d in range(0,m):\n",
        "        cuda.syncthreads()\n",
        "        k = local_id * 2**(d+1) + (blockIdx_x) * (blockDimx_x)\n",
        "        if (local_id * 2**(d+1)<= N-1):\n",
        "          s_tab[k+(2**(d+1)-1)]+= s_tab[k+(2**(d)-1)]\n",
        "  \n",
        "      cuda.syncthreads()\n",
        "      if local_id == 0:\n",
        "        sum_tab[blockIdx_x] = s_tab[((blockIdx_x) * (blockDimx_x))+blockDimx_x-1]\n",
        "        s_tab[((blockIdx_x) * (blockDimx_x))+blockDimx_x-1]=0\n",
        "     \n",
        "      # Descente\n",
        "      for d in range (m-1,-1,-1) :\n",
        "          cuda.syncthreads()\n",
        "          k = local_id * 2**(d+1) + (blockIdx_x) * (blockDimx_x)\n",
        "          if (local_id * 2**(d+1) <= N-1):\n",
        "            t = s_tab[k+(2**d)-1]\n",
        "            s_tab[k+(2**d)-1] = s_tab[k+(2**(d+1))-1]\n",
        "            s_tab[k+(2**(d+1))-1]+= t\n",
        "  \n",
        "\n",
        "def ScanCPU_Special(array,m,N):\n",
        "    #m=int(math.log2(len(array))\n",
        "    for d in range(0,m):\n",
        "        for k in range (0,N-1,(2**(d+1))):\n",
        "            array[k+(2**(d+1))-1]+= array[k+(2**d)-1]\n",
        "\n",
        "    array[N-1]=0\n",
        "    for d in range (m-1,-1,-1) :\n",
        "        for k in range (0,N-1,2**(d+1)) :\n",
        "            t = array[k+(2**d)-1]\n",
        "            array[k+(2**d)-1]= array[k+(2**(d+1))-1]\n",
        "            array[k+(2**(d+1))-1]+= t\n",
        "    return array\n",
        "\n",
        "\n",
        "def scanGPU(p):\n",
        "  print(\"SCAN GPU\",p)\n",
        "  N=len(p) # taille du tableau\n",
        "  print(N)\n",
        "  m= int(log2(N)) # 2^m = N\n",
        "  threadsPerBlock= 2 #1 seule  thread par grilles pour les tableau de petites tailles\n",
        "  blocksPerGrid= math.ceil(N/threadsPerBlock)\n",
        "  print(\"TPB\",threadsPerBlock,\"BPG\",blocksPerGrid)\n",
        "   \n",
        "  if(log2(N)%2 != 0):  \n",
        "    for i in range((N-threadsPerBlock),threadsPerBlock):\n",
        "       p = np.append(p,0)\n",
        "  print(p)\n",
        "  s_tab = cuda.to_device(p)\n",
        "\n",
        "  array2 = np.arange(0, blocksPerGrid, 1)\n",
        "  sum_tab = cuda.to_device(array2)\n",
        "  kernel[blocksPerGrid,threadsPerBlock](s_tab,threadsPerBlock,int(log2(threadsPerBlock)),sum_tab)\n",
        "  cuda.synchronize()\n",
        "  result = s_tab.copy_to_host()\n",
        "  res_sum_tab = sum_tab.copy_to_host()\n",
        "  res_copy = result.copy()\n",
        "  scan_res_sum = ScanCPU_Special(res_sum_tab.copy(),int(log2(len(res_sum_tab))),len(res_sum_tab))\n",
        "\n",
        "  print(\"RES_COPY\",res_copy)    \n",
        "  print(\"scan_res_sum\",scan_res_sum)\n",
        "\n",
        "  cpt = 0\n",
        "  for i in range(0,len(res_copy)):\n",
        "    if i>0 and i%threadsPerBlock==0:\n",
        "      cpt = cpt+1\n",
        "    temp = res_copy[i] + scan_res_sum[cpt]\n",
        "    res_copy[i] = temp\n",
        "  res_copy = res_copy[0:N]      \n",
        "  return res_copy\n",
        "\n",
        "\n",
        "def main():\n",
        "  \n",
        "    array = np.array([[5,3,2,4],[3,2,4,1],[4,8,3,1]])\n",
        "    print(\"INITIAL\",array)\n",
        "    new_array = []\n",
        "    #Pour chaque ligne de la matrice\n",
        "    for p in array:\n",
        "      new_array.append(scanGPU(p))\n",
        "      \n",
        "      # Si la taille du tableau est inférieur à 32\n",
        "      \"\"\"\n",
        "      if (N<=32):\n",
        "        result = ScanCPU_Special(array,int(log2(N)),N)\n",
        "        print(\"( GPU : \",result, \" )\")\n",
        "      else:\n",
        "      \"\"\"  \n",
        "     \n",
        "    np_arr = np.array(new_array)\n",
        "    print(\"new array\",np_arr)\n",
        "\n",
        "    trspose_arr = transpose(np_arr)\n",
        "    trspose_arr = trspose_arr.copy_to_host()\n",
        "    step2_array = []\n",
        "    print(trspose_arr)\n",
        "    cuda.synchronize()\n",
        "    \n",
        "    for p in trspose_arr:\n",
        "      step2_array.append(scanGPU(p))\n",
        "    print(step2_array)\n",
        "    step2_array = np.array(step2_array)\n",
        "    new_trspose_arr = transpose(step2_array)\n",
        "    new_trspose_arr = new_trspose_arr.copy_to_host()\n",
        "    print(new_trspose_arr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "LiWhs_CLMebD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5045d6e-f8b2-44bd-df91-4f5c59d18563"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INITIAL [[5 3 2 4]\n",
            " [3 2 4 1]\n",
            " [4 8 3 1]]\n",
            "SCAN GPU [5 3 2 4]\n",
            "4\n",
            "TPB 2 BPG 2\n",
            "[5 3 2 4]\n",
            "RES_COPY [0 5 0 2]\n",
            "scan_res_sum [0 8]\n",
            "SCAN GPU [3 2 4 1]\n",
            "4\n",
            "TPB 2 BPG 2\n",
            "[3 2 4 1]\n",
            "RES_COPY [0 3 0 4]\n",
            "scan_res_sum [0 5]\n",
            "SCAN GPU [4 8 3 1]\n",
            "4\n",
            "TPB 2 BPG 2\n",
            "[4 8 3 1]\n",
            "RES_COPY [0 4 0 3]\n",
            "scan_res_sum [ 0 12]\n",
            "new array [[ 0  5  8 10]\n",
            " [ 0  3  5  9]\n",
            " [ 0  4 12 15]]\n",
            "[[ 0  0  0]\n",
            " [ 5  3  4]\n",
            " [ 8  5 12]\n",
            " [10  9 15]]\n",
            "SCAN GPU [0 0 0]\n",
            "3\n",
            "TPB 2 BPG 2\n",
            "[0 0 0 0]\n",
            "RES_COPY [0 0 0 0]\n",
            "scan_res_sum [0 0]\n",
            "SCAN GPU [5 3 4]\n",
            "3\n",
            "TPB 2 BPG 2\n",
            "[5 3 4 0]\n",
            "RES_COPY [0 5 0 4]\n",
            "scan_res_sum [0 8]\n",
            "SCAN GPU [ 8  5 12]\n",
            "3\n",
            "TPB 2 BPG 2\n",
            "[ 8  5 12  0]\n",
            "RES_COPY [ 0  8  0 12]\n",
            "scan_res_sum [ 0 13]\n",
            "SCAN GPU [10  9 15]\n",
            "3\n",
            "TPB 2 BPG 2\n",
            "[10  9 15  0]\n",
            "RES_COPY [ 0 10  0 15]\n",
            "scan_res_sum [ 0 19]\n",
            "[array([0, 0, 0]), array([0, 5, 8]), array([ 0,  8, 13]), array([ 0, 10, 19])]\n",
            "[[ 0  0  0  0]\n",
            " [ 0  5  8 10]\n",
            " [ 0  8 13 19]]\n"
          ]
        }
      ]
    }
  ]
}